{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer TensorFlow et d'autres bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "folderName = 'datasets/garbage_ds'\n",
    "\n",
    "# Données d'entrainement\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  folderName,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "# Données de validation\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  folderName,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardiser les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurer l'ensemble de données pour les performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation virtuelle des données d'entrainement\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des données \"augmentées\"\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_images[10].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de classes d'éléments à détecter\n",
    "num_classes = len(class_names)\n",
    "\n",
    "model = tf.keras.Sequential(name=\"ALYRA-IA-DEV-PROJET-E1-EDOUNZE-CHARLES\")\n",
    "\n",
    "# Cette première couche applique des transformations aléatoires aux images d'entrée (comme la rotation, le zoom, le décalage) \n",
    "# pour augmenter la diversité du jeu de données d'entraînement sans avoir besoin de plus d'images. Cela aide le modèle à généraliser mieux à partir de données limitées.\n",
    "model.add(data_augmentation)\n",
    "\n",
    "# Cette couche normalise les images d'entrée en divisant les valeurs des pixels par 255. \n",
    "# Cela transforme les valeurs de pixels de la plage [0, 255] à [0, 1], ce qui est une pratique courante pour faciliter l'apprentissage du modèle.\n",
    "model.add(tf.keras.layers.Rescaling(1./255))\n",
    "\n",
    "# Première couche de convolution qui applique 32 filtres de 3x3 sur l'image d'entrée pour extraire des caractéristiques de bas niveau comme les bords. \n",
    "# La fonction d'activation 'relu' ajoute de la non-linéarité, permettant à la couche d'apprendre des motifs complexes.\n",
    "model.add(tf.keras.layers.Conv2D(32, 3, activation='relu'))\n",
    "\n",
    "# Ces couches suivent généralement les couches Conv2D et servent à réduire la dimensionnalité spatiale de la couche Conv2D précédente, en conservant les caractéristiques les plus importantes. \n",
    "# Elles aident à rendre le modèle plus efficace et à diminuer le risque de surajustement (overfitting) en extrayant les caractéristiques les plus saillantes.\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "\n",
    "# Deuxième couche de convolution qui applique à nouveau 32 filtres de 3x3. \n",
    "# À ce stade, le modèle cherche à extraire des caractéristiques plus complexes à partir des informations simplifiées par la première couche de MaxPooling.\n",
    "model.add(tf.keras.layers.Conv2D(32, 3, activation='relu'))\n",
    "\n",
    "# Agit sur la sortie de la deuxième couche Conv2D pour réduire encore la dimensionnalité. \n",
    "# Cette étape continue de condenser l'information, permettant au modèle de devenir progressivement plus abstrait et concentré sur les caractéristiques saillantes (remarquables).\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "\n",
    "# Troisième couche de convolution identique aux précédentes en termes de nombre de filtres et de taille, \n",
    "# poussant le modèle à extraire et à apprendre des caractéristiques encore plus abstraites des données\n",
    "model.add(tf.keras.layers.Conv2D(32, 3, activation='relu'))\n",
    "\n",
    "# Appliquée après la troisième couche Conv2D, cette couche de pooling continue de réduire la dimensionnalité de la représentation de l'image, \n",
    "# préparant les données pour une analyse de haut niveau dans les couches suivantes.\n",
    "tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "# Cette couche ignore aléatoirement 20% des neurones durant l'entraînement, réduisant ainsi le surajustement en forçant \n",
    "# le modèle à apprendre des caractéristiques plus robustes qui ne dépendent pas d'un petit nombre de neurones.\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "# Cette couche aplatie les matrices multidimensionnelles en vecteurs unidimensionnels, \n",
    "# permettant de passer de représentations spatiales à un format compatible avec les couches denses.\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Une couche dense (ou entièrement connectée) qui a 128 neurones et utilise ReLU comme fonction d'activation. \n",
    "# Cette couche permet au modèle de combiner les caractéristiques apprises par les couches précédentes pour former des abstractions de plus haut niveau.\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "# La dernière couche dense avec un nombre de neurones égal au nombre de classes dans le jeu de données. \n",
    "# Elle génère la sortie du modèle, où chaque neurone représente la probabilité que l'image d'entrée appartienne à une classe spécifique.\n",
    "model.add(tf.keras.layers.Dense(num_classes))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  # Cette première couche applique des transformations aléatoires aux images d'entrée (comme la rotation, le zoom, le décalage) \n",
    "  # pour augmenter la diversité du jeu de données d'entraînement sans avoir besoin de plus d'images. Cela aide le modèle à généraliser mieux à partir de données limitées.\n",
    "  data_augmentation,\n",
    "  \n",
    "  # Cette couche normalise les images d'entrée en divisant les valeurs des pixels par 255. \n",
    "  # Cela transforme les valeurs de pixels de la plage [0, 255] à [0, 1], ce qui est une pratique courante pour faciliter l'apprentissage du modèle.\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "\n",
    "  # Plusieurs de ces couches appliquent des filtres (ou noyaux) pour capturer des caractéristiques spatiales dans les images. \n",
    "  # Chaque couche Conv2D ici utilise 32 filtres de taille 3x3 et une fonction d'activation ReLU pour introduire des non-linéarités. \n",
    "  # Ces couches aident le modèle à apprendre différents aspects visuels des images, comme les bords, les textures, ou d'autres motifs.\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "\n",
    "  # Ces couches suivent généralement les couches Conv2D et servent à réduire la dimensionnalité spatiale des représentations d'entrée. \n",
    "  # Elles aident à rendre le modèle plus efficace et à diminuer le risque de surajustement en extrayant les caractéristiques les plus saillantes.\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "  # Cette couche ignore aléatoirement 20% des neurones durant l'entraînement, réduisant ainsi le surajustement en forçant \n",
    "  # le modèle à apprendre des caractéristiques plus robustes qui ne dépendent pas d'un petit nombre de neurones.\n",
    "  layers.Dropout(0.2),\n",
    "\n",
    "  # Cette couche aplatie les matrices multidimensionnelles en vecteurs unidimensionnels, \n",
    "  # permettant de passer de représentations spatiales à un format compatible avec les couches denses.\n",
    "  tf.keras.layers.Flatten(),\n",
    "\n",
    "  # Une couche dense (ou entièrement connectée) qui a 128 neurones et utilise ReLU comme fonction d'activation. \n",
    "  # Cette couche permet au modèle de combiner les caractéristiques apprises par les couches précédentes pour former des abstractions de plus haut niveau.\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "\n",
    "  #  La dernière couche dense avec un nombre de neurones égal au nombre de classes dans le jeu de données. \n",
    "  # Elle génère la sortie du modèle, où chaque neurone représente la probabilité que l'image d'entrée appartienne à une classe spécifique.\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=15\n",
    "\n",
    "history  = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résultats de l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction de nouvelles données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_url = \"https://www.francetvinfo.fr/pictures/WCd2DGgauBIkM2KDQcLfNrjIois/1500x843/2023/01/30/63d7748135eff_maxnewsfrfour319227.jpg\"\n",
    "object_path = tf.keras.utils.get_file('Object_image', origin=object_url)\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    object_path, target_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "print(type(img))\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
