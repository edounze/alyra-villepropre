{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer TensorFlow et d'autres bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pathlib\n",
    "# import os\n",
    "# import PIL\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Rescaling, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, RandomFlip, RandomRotation, RandomZoom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "folderName = 'datasets/'\n",
    "\n",
    "# Données d'entrainement (X)\n",
    "X_train = keras.utils.image_dataset_from_directory(\n",
    "  folderName,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "# Données de validation (Y)\n",
    "val_ds = keras.utils.image_dataset_from_directory(\n",
    "  folderName,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "\n",
    "class_names = X_train.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in X_train.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in X_train:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardiser les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization_layer = Rescaling(1./255)\n",
    "\n",
    "# # Normalisation des données en entrée\n",
    "# X_train = X_train.map(lambda x, y: (normalization_layer(x), y))\n",
    "# image_batch, labels_batch = next(iter(X_train))\n",
    "# first_image = image_batch[0]\n",
    "\n",
    "# print(np.min(first_image), np.max(first_image)) # Les valeurs de pixel sont désormais entre `[0,1]`.\n",
    "\n",
    "# # Normalisation des données de validation\n",
    "# val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurer l'ensemble de données pour les performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "X_train = X_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation virtuelle des données d'entrainement\n",
    "\n",
    "data_augmentation = Sequential(\n",
    "  [\n",
    "    RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    RandomRotation(0.1),\n",
    "    RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des données \"augmentées\"\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in X_train.take(1):\n",
    "  for i in range(9):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_images[10].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de classes d'éléments à détecter\n",
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential(name=\"ALYRA-IA-DEV-PROJET-E1-EDOUNZE-CHARLES\")\n",
    "\n",
    "# On définit clairement la forme d'entrée attendue par le modèle. \n",
    "# Chaque image d'entrée sera de taille 180x180 avec 3 canaux (couleur RGB).\n",
    "model.add(Input(shape=(img_height, img_width, 3)))\n",
    "\n",
    "# Cette couche applique des transformations aléatoires aux images d'entrée (comme la rotation, le zoom, le décalage) \n",
    "# pour augmenter la diversité du jeu de données d'entraînement sans avoir besoin de plus d'images. Cela aide le modèle à généraliser mieux à partir de données limitées.\n",
    "model.add(data_augmentation)\n",
    "\n",
    "# Cette couche normalise les images d'entrée en divisant les valeurs des pixels par 255. \n",
    "# Cela transforme les valeurs de pixels de la plage [0, 255] à [0, 1]\n",
    "model.add(Rescaling(1./255))\n",
    "\n",
    "# Première couche de convolution qui applique 128 filtres de 3x3 sur l'image d'entrée pour extraire des caractéristiques de bas niveau comme les bords. \n",
    "# La fonction d'activation 'relu' ajoute de la non-linéarité, permettant à la couche d'apprendre des motifs complexes.\n",
    "model.add(Conv2D(128, 3, activation='relu'))\n",
    "\n",
    "# Ces couches suivent généralement les couches Conv2D et servent à réduire la dimensionnalité spatiale de la couche Conv2D précédente, en conservant les caractéristiques les plus importantes. \n",
    "# Elles aident à rendre le modèle plus efficace et à diminuer le risque de surajustement (overfitting) en extrayant les caractéristiques les plus saillantes.\n",
    "model.add(MaxPooling2D())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), strides=(3, 3)))\n",
    "\n",
    "# Deuxième couche de convolution qui applique à nouveau 64 filtres de 3x3. \n",
    "# À ce stade, le modèle cherche à extraire des caractéristiques plus complexes à partir des informations simplifiées par la première couche de MaxPooling.\n",
    "model.add(Conv2D(64, 3, activation='relu'))\n",
    "\n",
    "# Agit sur la sortie de la deuxième couche Conv2D pour réduire encore la dimensionnalité. \n",
    "# Cette étape continue de condenser l'information, permettant au modèle de devenir progressivement plus abstrait et concentré sur les caractéristiques saillantes (remarquables).\n",
    "# model.add(MaxPooling2D())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(3, 3)))\n",
    "\n",
    "\n",
    "# Troisième couche de convolution qui applique à nouveau 32 filtres de 3x3. \n",
    "# poussant le modèle à extraire et à apprendre des caractéristiques encore plus abstraites des données\n",
    "model.add(Conv2D(32, 3, activation='relu'))\n",
    "\n",
    "# Appliquée après la troisième couche Conv2D, cette couche de pooling continue de réduire la dimensionnalité de la représentation de l'image, \n",
    "# préparant les données pour une analyse de haut niveau dans les couches suivantes.\n",
    "# MaxPooling2D()\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(3, 3)))\n",
    "\n",
    "# Cette couche ignore aléatoirement 20% des neurones durant l'entraînement, réduisant ainsi le surajustement en forçant \n",
    "# le modèle à apprendre des caractéristiques plus robustes qui ne dépendent pas d'un petit nombre de neurones.\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Cette couche aplatie les matrices multidimensionnelles en vecteurs unidimensionnels, \n",
    "# permettant de passer de représentations spatiales à un format compatible avec les couches denses.\n",
    "model.add(Flatten())\n",
    "\n",
    "# Une couche dense (ou entièrement connectée) qui a 128 neurones et utilise ReLU comme fonction d'activation. \n",
    "# Cette couche permet au modèle de combiner les caractéristiques apprises par les couches précédentes pour former des abstractions de plus haut niveau.\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Dernière couche dense avec un nombre de neurones égal au nombre de classes dans le jeu de données. \n",
    "# Elle génère la sortie du modèle, où chaque neurone représente la probabilité que l'image d'entrée appartienne à une classe spécifique.\n",
    "model.add(Dense(num_classes, activation='softmax', name='output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Détails du modèle\n",
    "print('Nombre de couches : ', len(model.weights))\n",
    "model.summary()\n",
    "\n",
    "# Affichage du modèle\n",
    "keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True, dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=25\n",
    "# callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),\n",
    "# ]\n",
    "\n",
    "history  = model.fit(\n",
    "  X_train,  # input data\n",
    "  validation_data=val_ds,  # target data\n",
    "  epochs=epochs\n",
    "  # callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résultats de l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction de nouvelles données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def doPrediction(imgToPredict, model=model):\n",
    "    img_array = keras.utils.img_to_array(imgToPredict)\n",
    "    img_array = tf.expand_dims(img_array, 0) # Create batch axis\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "    print(\n",
    "        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "        .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "    )\n",
    "\n",
    "    plt.imshow(imgToPredict)\n",
    "    \n",
    "object_url = \"https://us.123rf.com/450wm/nito500/nito5001011/nito500101100005/8110733-bouteille-en-plastique-%C3%A9cras%C3%A9-isol%C3%A9-sur-un-fond-blanc-sur-un-fond-blanc.jpg\"\n",
    "object_path = keras.utils.get_file('Object_image', origin=object_url)\n",
    "\n",
    "img = keras.utils.load_img(object_path, target_size=(img_height, img_width))\n",
    "\n",
    "# Do prediction !\n",
    "doPrediction(img)\n",
    "\n",
    "\n",
    "# img_array = keras.utils.img_to_array(img)\n",
    "# img_array = tf.expand_dims(img_array, 0) # Create batch axis\n",
    "\n",
    "# predictions = model.predict(img_array)\n",
    "# score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "# print(\n",
    "#     \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "#     .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "# )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/garbage_detection_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réutilisation du modèle sauvegardé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSaved = tf.keras.models.load_model(\"garbage_detection_model.keras\")\n",
    "\n",
    "# loss, acc = modelSaved.evaluate(val_ds)\n",
    "# print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "\n",
    "# New prediction ! (Inference)\n",
    "object_url = \"https://t3.ftcdn.net/jpg/00/61/65/50/360_F_61655074_7J7dl9Ejn9jDPGAwrurHJWbiT86Tqblo.jpg\"\n",
    "object_path = keras.utils.get_file('Object_image', origin=object_url)\n",
    "\n",
    "newImg = keras.utils.load_img(object_path, target_size=(img_height, img_width))\n",
    "doPrediction(newImg, model=modelSaved)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
